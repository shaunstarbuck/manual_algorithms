{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import cholesky, det, lstsq\n",
    "from scipy.optimize import minimize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(X, noise=0.2):\n",
    "    return -np.sin(3*X) - X**2 + 0.7*X + noise * np.random.randn(*X.shape)\n",
    "\n",
    "X_train = np.array([[-0.9], [0], [0.5], [0.9], [1.1]])\n",
    "Y_train = f(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From gausian process\n",
    "noise = 0.4\n",
    "# Noisy training data\n",
    "X_train = np.arange(-3, 4, 1).reshape(-1, 1)\n",
    "Y_train = np.sin(X_train) + noise * np.random.randn(*X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RBF_noise_kernel(X1, X2, l = 1.0, sigma_f = 1.0, sigma_y = 1.0):\n",
    "    '''\n",
    "    Isotropic squared exponential kernal (radial basis function kernel). Computes\n",
    "    a covariance matrix from points in X1 and X2.\n",
    "    Args:\n",
    "        X1: Array of m points \n",
    "        X2: array of n points\n",
    "        sigma_f: variance of the Gaussian Process\n",
    "        sigma_y: noise variance\n",
    "    Returns:\n",
    "        Covariance matrix(m X n).\n",
    "    '''\n",
    "    sqdist = np.sum(X1**2, 1).reshape(-1,1) + np.sum(X2**2, 1) -  2 * np.dot(X1, X2.T)\n",
    "    return sigma_f**2 * np.exp(-0.5 / l**2 * sqdist) + sigma_y**2 * np.eye(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_predictive(X_s, X_train, Y_train, l = 1.0, sigma_f = 1.0, sigma_y = 1e-8, kernel = RBF_noise_kernel):\n",
    "    '''\n",
    "    Computes the suffifient statistics of the GP posterior predictive distribution \n",
    "    from m training data X_train and Y_train and n new inputs X_s.\n",
    "    \n",
    "    Args:\n",
    "        X_s: New input locations (n x d).\n",
    "        X_train: Training locations (m x d).\n",
    "        Y_train: Training targets (m x 1).\n",
    "        l: Kernel length parameter.\n",
    "        sigma_f: Kernel vertical variation parameter.\n",
    "        sigma_y: Noise parameter.\n",
    "        kernel: kernel function for the GP\n",
    "    Returns:\n",
    "        Posterior mean vector (n x d) and covariance matrix (n x n).\n",
    "    '''\n",
    "    #Create kernel with noise added along the matrix diagonal\n",
    "    K = kernel(X_train, X_train, l, sigma_f) + sigma_y**2 * np.eye(len(X_train))\n",
    "    #Get covariance of new inputs from X_train\n",
    "    K_s = kernel(X_train, X_s, l , sigma_f)\n",
    "    #Get Covariance of new inputs, with noise\n",
    "    K_ss = kernel(X_s, X_s, l, sigma_f) + 1e-8 * np.eye(len(X_s))\n",
    "    #get inverse of X_train covariance matrix\n",
    "    K_inv = inv(K)\n",
    "    \n",
    "    #Calculate mean of the posterior predictive distribution \n",
    "    mu_s = K_s.T.dot(K_inv).dot(Y_train)\n",
    "    \n",
    "    #Calculate covariance matrix of the posterior predictive distribution \n",
    "    cov_s = K_ss - K_s.T.dot(K_inv).dot(K_s)\n",
    "    \n",
    "    return mu_s, cov_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_full_fn(X_train, Y_train, naive=True):\n",
    "    '''\n",
    "    Returns a function that computes the negative log marginal\n",
    "    likelihood for training data X_train and Y_train and an unknown \n",
    "    noise level.\n",
    "    \n",
    "    Args:\n",
    "        X_train: training locations (m x d).\n",
    "        Y_train: training targets (m x 1).\n",
    "        naive: if True use a naive implementation of Eq. (7), if \n",
    "               False use a numerically more stable implementation. \n",
    "        \n",
    "    Returns:\n",
    "        Minimization objective.\n",
    "    '''\n",
    "    def nll_naive(theta):\n",
    "        # Naive implementation of the equation for log marginal likeliehood. Works well for simple examples \n",
    "        # but is numerically less stable compared to \n",
    "        # the implementation in nll_stable below.\n",
    "        K = RBF_noise_kernel(X_train, X_train, l=theta[0], sigma_f=theta[1], sigma_y=theta[2])\n",
    "        return 0.5 * np.log(det(K)) + \\\n",
    "               0.5 * Y_train.T.dot(inv(K).dot(Y_train)) + \\\n",
    "               0.5 * len(X_train) * np.log(2*np.pi)\n",
    "\n",
    "    def nll_stable(theta):\n",
    "        # Numerically more stable implementation of  equation for log marginal likeliehood as described\n",
    "        # in http://www.gaussianprocess.org/gpml/chapters/RW2.pdf, Section\n",
    "        # 2.2, Algorithm 2.1.\n",
    "        K = RBF_noise_kernel(X_train, X_train, l=theta[0], sigma_f=theta[1], sigma_y=theta[2])\n",
    "        L = cholesky(K)\n",
    "        return np.sum(np.log(np.diagonal(L))) + \\\n",
    "               0.5 * Y_train.T.dot(lstsq(L.T, lstsq(L, Y_train)[0])[0]) + \\\n",
    "               0.5 * len(X_train) * np.log(2*np.pi)\n",
    "    \n",
    "    if naive:\n",
    "        return nll_naive\n",
    "    else:\n",
    "        return nll_stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30236826, 2.83677018, 2.46866433],\n",
       "       [2.96706861, 2.85925018, 0.48631937],\n",
       "       [0.59720531, 1.37948338, 1.74794257],\n",
       "       [1.58518244, 0.83395748, 0.80328647],\n",
       "       [0.47021669, 1.17329281, 0.0556069 ],\n",
       "       [2.30391256, 2.95953616, 2.27445386],\n",
       "       [2.11712173, 2.92409832, 0.64623414],\n",
       "       [2.72241668, 2.47795056, 2.0166069 ],\n",
       "       [1.02469957, 0.90201921, 2.77242865],\n",
       "       [0.76693407, 2.59673768, 2.40535385]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform(0, 3, size=(10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize(nll_full_fn(X_train, Y_train), [1,1,1], \n",
    "              bounds = ((1e-5, None), (1e-5, None),(1e-5, None)),\n",
    "              method = 'L-BFGS-B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.29278952e+02, 4.17307164e-01, 4.09714360e-01])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\higgleop\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.54445338]]\n",
      "[[3.21051944]]\n",
      "[[3.5444546]]\n",
      "[[3.21051944]]\n",
      "[[3.54445143]]\n",
      "[[3.54447071]]\n",
      "[[3.54445855]]\n",
      "[[3.54445539]]\n",
      "[[3.21051944]]\n",
      "[[3.54445757]]\n",
      "[[3.21051944]]\n",
      "[[3.54446385]]\n",
      "[[3.54446273]]\n",
      "[[3.54447618]]\n",
      "[[3.54446047]]\n",
      "[[3.21051944]]\n",
      "[[3.54445364]]\n",
      "[[3.5444509]]\n",
      "[[3.54445429]]\n",
      "[[3.21051944]]\n"
     ]
    }
   ],
   "source": [
    "# Minimize the negative log-likelihood w.r.t. parameters l, sigma_f, and sigma_y.\n",
    "# Can run the minimization several times with different\n",
    "# initializations to avoid local minima.\n",
    "dim = 3\n",
    "min_val = 1\n",
    "min_x = None\n",
    "n_restarts = 20\n",
    "\n",
    "# Find the best optimum by starting from n_restart different random points.\n",
    "for x0 in np.random.uniform(0, 2, size=(n_restarts, dim)):\n",
    "        #res = minimize(min_obj, x0=x0, bounds=bounds, method='L-BFGS-B')        \n",
    "    res = minimize(nll_full_fn(X_train, Y_train, naive= False), x0 = x0, \n",
    "        bounds = ((1e-5, None), (1e-5, None),(1e-5, None)),\n",
    "        method = 'L-BFGS-B')\n",
    "    print(res.fun)\n",
    "    if res.fun < min_val:\n",
    "        min_val = res.fun[0]\n",
    "        min_x = res.x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.11429720e-01, 6.15610008e-01, 1.00000000e-05])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
